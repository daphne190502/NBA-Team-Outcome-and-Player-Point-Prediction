{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9659a1ed-c1d0-4792-939f-126991110a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e65a72-ef4c-4c88-b0f0-0e73ca13497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_csv(r\"C:\\Users\\Daphne\\OneDrive\\Documents\\NBA data set\\games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c7e54b-b26c-4a60-a928-df2e5ff72404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_DATE_EST</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_STATUS_TEXT</th>\n",
       "      <th>HOME_TEAM_ID</th>\n",
       "      <th>VISITOR_TEAM_ID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEAM_ID_home</th>\n",
       "      <th>PTS_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>...</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>TEAM_ID_away</th>\n",
       "      <th>PTS_away</th>\n",
       "      <th>FG_PCT_away</th>\n",
       "      <th>FT_PCT_away</th>\n",
       "      <th>FG3_PCT_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>HOME_TEAM_WINS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>22200477</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>1610612759</td>\n",
       "      <td>2022</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.926</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1610612759</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.321</td>\n",
       "      <td>23.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>22200478</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612762</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>2022</td>\n",
       "      <td>1610612762</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.952</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>22200466</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>1610612749</td>\n",
       "      <td>2022</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.786</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1610612749</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.433</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>22200467</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>1610612765</td>\n",
       "      <td>2022</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.909</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1610612765</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.261</td>\n",
       "      <td>15.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>22200468</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>1610612741</td>\n",
       "      <td>2022</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1610612741</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.292</td>\n",
       "      <td>20.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26646</th>\n",
       "      <td>2014-10-06</td>\n",
       "      <td>11400007</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>2014</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.821</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.375</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26647</th>\n",
       "      <td>2014-10-06</td>\n",
       "      <td>11400004</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612741</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>2014</td>\n",
       "      <td>1610612741</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.719</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.267</td>\n",
       "      <td>17.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26648</th>\n",
       "      <td>2014-10-06</td>\n",
       "      <td>11400005</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>1610612743</td>\n",
       "      <td>2014</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.682</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1610612743</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.500</td>\n",
       "      <td>19.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26649</th>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>11400002</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612761</td>\n",
       "      <td>1610612758</td>\n",
       "      <td>2014</td>\n",
       "      <td>1610612761</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.771</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1610612758</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.385</td>\n",
       "      <td>18.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26650</th>\n",
       "      <td>2014-10-04</td>\n",
       "      <td>11400001</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612748</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>2014</td>\n",
       "      <td>1610612748</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.679</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.438</td>\n",
       "      <td>19.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26651 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GAME_DATE_EST   GAME_ID GAME_STATUS_TEXT  HOME_TEAM_ID  VISITOR_TEAM_ID  \\\n",
       "0        2022-12-22  22200477            Final    1610612740       1610612759   \n",
       "1        2022-12-22  22200478            Final    1610612762       1610612764   \n",
       "2        2022-12-21  22200466            Final    1610612739       1610612749   \n",
       "3        2022-12-21  22200467            Final    1610612755       1610612765   \n",
       "4        2022-12-21  22200468            Final    1610612737       1610612741   \n",
       "...             ...       ...              ...           ...              ...   \n",
       "26646    2014-10-06  11400007            Final    1610612737       1610612740   \n",
       "26647    2014-10-06  11400004            Final    1610612741       1610612764   \n",
       "26648    2014-10-06  11400005            Final    1610612747       1610612743   \n",
       "26649    2014-10-05  11400002            Final    1610612761       1610612758   \n",
       "26650    2014-10-04  11400001            Final    1610612748       1610612740   \n",
       "\n",
       "       SEASON  TEAM_ID_home  PTS_home  FG_PCT_home  FT_PCT_home  ...  \\\n",
       "0        2022    1610612740     126.0        0.484        0.926  ...   \n",
       "1        2022    1610612762     120.0        0.488        0.952  ...   \n",
       "2        2022    1610612739     114.0        0.482        0.786  ...   \n",
       "3        2022    1610612755     113.0        0.441        0.909  ...   \n",
       "4        2022    1610612737     108.0        0.429        1.000  ...   \n",
       "...       ...           ...       ...          ...          ...  ...   \n",
       "26646    2014    1610612737      93.0        0.419        0.821  ...   \n",
       "26647    2014    1610612741      81.0        0.338        0.719  ...   \n",
       "26648    2014    1610612747      98.0        0.448        0.682  ...   \n",
       "26649    2014    1610612761      99.0        0.440        0.771  ...   \n",
       "26650    2014    1610612748      86.0        0.431        0.679  ...   \n",
       "\n",
       "       AST_home  REB_home  TEAM_ID_away  PTS_away  FG_PCT_away  FT_PCT_away  \\\n",
       "0          25.0      46.0    1610612759     117.0        0.478        0.815   \n",
       "1          16.0      40.0    1610612764     112.0        0.561        0.765   \n",
       "2          22.0      37.0    1610612749     106.0        0.470        0.682   \n",
       "3          27.0      49.0    1610612765      93.0        0.392        0.735   \n",
       "4          22.0      47.0    1610612741     110.0        0.500        0.773   \n",
       "...         ...       ...           ...       ...          ...          ...   \n",
       "26646      24.0      50.0    1610612740      87.0        0.366        0.643   \n",
       "26647      18.0      40.0    1610612764      85.0        0.411        0.636   \n",
       "26648      29.0      45.0    1610612743      95.0        0.387        0.659   \n",
       "26649      21.0      30.0    1610612758      94.0        0.469        0.725   \n",
       "26650      18.0      42.0    1610612740      98.0        0.462        0.706   \n",
       "\n",
       "       FG3_PCT_away  AST_away  REB_away  HOME_TEAM_WINS  \n",
       "0             0.321      23.0      44.0               1  \n",
       "1             0.333      20.0      37.0               1  \n",
       "2             0.433      20.0      46.0               1  \n",
       "3             0.261      15.0      46.0               1  \n",
       "4             0.292      20.0      47.0               0  \n",
       "...             ...       ...       ...             ...  \n",
       "26646         0.375      17.0      43.0               1  \n",
       "26647         0.267      17.0      47.0               0  \n",
       "26648         0.500      19.0      43.0               1  \n",
       "26649         0.385      18.0      45.0               1  \n",
       "26650         0.438      19.0      42.0               0  \n",
       "\n",
       "[26651 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b47010-0793-43fc-95e2-652dfe5ba8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in games dataset: ['GAME_DATE_EST', 'GAME_ID', 'GAME_STATUS_TEXT', 'HOME_TEAM_ID', 'VISITOR_TEAM_ID', 'SEASON', 'TEAM_ID_home', 'PTS_home', 'FG_PCT_home', 'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home', 'TEAM_ID_away', 'PTS_away', 'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away', 'HOME_TEAM_WINS']\n",
      "Missing values in games dataset:\n",
      "GAME_DATE_EST        0\n",
      "GAME_ID              0\n",
      "GAME_STATUS_TEXT     0\n",
      "HOME_TEAM_ID         0\n",
      "VISITOR_TEAM_ID      0\n",
      "SEASON               0\n",
      "TEAM_ID_home         0\n",
      "PTS_home            99\n",
      "FG_PCT_home         99\n",
      "FT_PCT_home         99\n",
      "FG3_PCT_home        99\n",
      "AST_home            99\n",
      "REB_home            99\n",
      "TEAM_ID_away         0\n",
      "PTS_away            99\n",
      "FG_PCT_away         99\n",
      "FT_PCT_away         99\n",
      "FG3_PCT_away        99\n",
      "AST_away            99\n",
      "REB_away            99\n",
      "HOME_TEAM_WINS       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the column names of the games dataset\n",
    "game_features = games.columns.tolist()\n",
    "print(\"Features in games dataset:\", game_features)\n",
    "\n",
    "# Check for missing values in the games dataset\n",
    "missing_values = games.isnull().sum()\n",
    "print(\"Missing values in games dataset:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8546e3-9d5e-4217-a356-480712b4d5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values: Index([19175, 19176, 19177, 19178, 19179, 19180, 19181, 19182, 19183, 19184,\n",
      "       19185, 19186, 19187, 19188, 19189, 19190, 19191, 19192, 19193, 19194,\n",
      "       19195, 19196, 19197, 19198, 19199, 19200, 19201, 19202, 19203, 19204,\n",
      "       19205, 19206, 19207, 19208, 19209, 19210, 19211, 19212, 19213, 19214,\n",
      "       19215, 19216, 19217, 19218, 19219, 19220, 19221, 19222, 19223, 19224,\n",
      "       19225, 19226, 19227, 19228, 19229, 19230, 19231, 19232, 19233, 19234,\n",
      "       19235, 19236, 19237, 19238, 19239, 19240, 19241, 19242, 19243, 19244,\n",
      "       19245, 19246, 19247, 19248, 19249, 19250, 19251, 19252, 19253, 19254,\n",
      "       19255, 19256, 19257, 19258, 19259, 19260, 19261, 19262, 19263, 19264,\n",
      "       19265, 19266, 19267, 19268, 19269, 19270, 19271, 19278, 19279],\n",
      "      dtype='int64')\n",
      "Are missing values consistent across these rows?: True\n"
     ]
    }
   ],
   "source": [
    "# Check which rows have missing values in the specific columns\n",
    "missing_values_rows = games[[\n",
    "    'PTS_home', 'FG_PCT_home', 'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home',\n",
    "    'PTS_away', 'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away'\n",
    "]].isnull().any(axis=1)\n",
    "\n",
    "# Extract the indices of rows with missing values\n",
    "missing_indices = games[missing_values_rows].index\n",
    "\n",
    "# Verify if the same rows have missing values across all the columns checked\n",
    "consistent_missing = all(\n",
    "    games.loc[missing_indices, [\n",
    "        'PTS_home', 'FG_PCT_home', 'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home',\n",
    "        'PTS_away', 'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away'\n",
    "    ]].isnull().all(axis=1)\n",
    ")\n",
    "\n",
    "print(\"Rows with missing values:\", missing_indices)\n",
    "print(\"Are missing values consistent across these rows?:\", consistent_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe38831a-6237-4713-9f8e-5ee81ad7a60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daphne\\AppData\\Local\\Temp\\ipykernel_1240\\634453159.py:1: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  games_details = pd.read_csv(r\"C:\\Users\\Daphne\\OneDrive\\Documents\\NBA data set\\games_details.csv\")\n"
     ]
    }
   ],
   "source": [
    "games_details = pd.read_csv(r\"C:\\Users\\Daphne\\OneDrive\\Documents\\NBA data set\\games_details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "134b4139-56a2-4c41-a151-12b6eabf3f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Game IDs: [10300116, 10300108, 10300109, 10300113, 10300112, 10300110, 10300111, 10300114, 10300115, 10300103, 10300106, 10300107, 10300104, 10300102, 10300105, 10300094, 10300095, 10300101, 10300097, 10300099, 10300096, 10300098, 10300100, 10300089, 10300091, 10300093, 10300090, 10300092, 10300085, 10300088, 10300087, 10300086, 10300080, 10300082, 10300083, 10300084, 10300081, 10300074, 10300077, 10300073, 10300079, 10300075, 10300076, 10300078, 10300069, 10300064, 10300071, 10300066, 10300067, 10300070, 10300068, 10300065, 10300072, 10300058, 10300062, 10300059, 10300060, 10300061, 10300063, 10300057, 10300054, 10300055, 10300056, 10300051, 10300049, 10300050, 10300048, 10300044, 10300052, 10300046, 10300053, 10300045, 10300047, 10300043, 10300042, 10300039, 10300040, 10300041, 10300034, 10300035, 10300036, 10300030, 10300031, 10300032, 10300033, 10300037, 10300038, 10300023, 10300027, 10300024, 10300025, 10300026, 10300020, 10300021, 10300019, 10300022, 10300013, 10300015, 10300006]\n",
      "Count of Missing Game IDs: 99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for game IDs in games dataset that are not in games_details dataset\n",
    "missing_game_ids = games[~games['GAME_ID'].isin(games_details['GAME_ID'])]['GAME_ID']\n",
    "\n",
    "# Count of missing game IDs\n",
    "missing_count = missing_game_ids.count()\n",
    "\n",
    "# Output the missing game IDs and their count\n",
    "print(\"Missing Game IDs:\", missing_game_ids.tolist())\n",
    "print(\"Count of Missing Game IDs:\", missing_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f35221-3cf3-47d2-a0c9-68f52bc82b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME_IDs missing in games_details: 99\n",
      "GAME_IDs missing in games: 0\n"
     ]
    }
   ],
   "source": [
    "#checking whether all the game id in the games data set are in the games_details data set \n",
    "# Extract unique GAME_IDs from both datasets\n",
    "games_game_ids = games['GAME_ID'].unique()\n",
    "games_details_game_ids = games_details['GAME_ID'].unique()\n",
    "\n",
    "# Find GAME_IDs in games not in games_details\n",
    "missing_in_details = set(games_game_ids) - set(games_details_game_ids)\n",
    "missing_in_details_count = len(missing_in_details)\n",
    "\n",
    "# Find GAME_IDs in games_details not in games\n",
    "missing_in_games = set(games_details_game_ids) - set(games_game_ids)\n",
    "missing_in_games_count = len(missing_in_games)\n",
    "\n",
    "# Output the results\n",
    "print(f\"GAME_IDs missing in games_details: {missing_in_details_count}\")\n",
    "print(f\"GAME_IDs missing in games: {missing_in_games_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fd35ab6-649b-4a02-81c8-9682416e1177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEAM_IDs missing in games_details: 0\n",
      "TEAM_IDs missing in games: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking whether all the team id in the games data set are in the games_details data set and vise versa.\n",
    "\n",
    "# Extract unique TEAM_IDs from the games dataset (both home and visitor)\n",
    "home_team_ids = games['HOME_TEAM_ID'].unique()\n",
    "visitor_team_ids = games['VISITOR_TEAM_ID'].unique()\n",
    "games_team_ids = set(home_team_ids).union(visitor_team_ids)\n",
    "\n",
    "# Extract unique TEAM_IDs from the games_details dataset\n",
    "details_team_ids = games_details['TEAM_ID'].unique()\n",
    "\n",
    "# Find TEAM_IDs in games not in games_details\n",
    "missing_teams_in_details = games_team_ids - set(details_team_ids)\n",
    "missing_teams_in_details_count = len(missing_teams_in_details)\n",
    "\n",
    "# Find TEAM_IDs in games_details not in games\n",
    "missing_teams_in_games = set(details_team_ids) - games_team_ids\n",
    "missing_teams_in_games_count = len(missing_teams_in_games)\n",
    "\n",
    "# Output the results\n",
    "print(f\"TEAM_IDs missing in games_details: {missing_teams_in_details_count}\")\n",
    "print(f\"TEAM_IDs missing in games: {missing_teams_in_games_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d01651ca-b94f-4caa-9c92-0eed8d376bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining GAME_IDs in games: 26523\n",
      "Remaining GAME_IDs in games_details: 26523\n"
     ]
    }
   ],
   "source": [
    "# List of missing GAME_IDs\n",
    "missing_game_ids = [10300116, 10300108, 10300109, 10300113, 10300112, 10300110, 10300111, 10300114, 10300115, 10300103, 10300106, 10300107, 10300104, 10300102, 10300105, 10300094, 10300095, 10300101, 10300097, 10300099, 10300096, 10300098, 10300100, 10300089, 10300091, 10300093, 10300090, 10300092, 10300085, 10300088, 10300087, 10300086, 10300080, 10300082, 10300083, 10300084, 10300081, 10300074, 10300077, 10300073, 10300079, 10300075, 10300076, 10300078, 10300069, 10300064, 10300071, 10300066, 10300067, 10300070, 10300068, 10300065, 10300072, 10300058, 10300062, 10300059, 10300060, 10300061, 10300063, 10300057, 10300054, 10300055, 10300056, 10300051, 10300049, 10300050, 10300048, 10300044, 10300052, 10300046, 10300053, 10300045, 10300047, 10300043, 10300042, 10300039, 10300040, 10300041, 10300034, 10300035, 10300036, 10300030, 10300031, 10300032, 10300033, 10300037, 10300038, 10300023, 10300027, 10300024, 10300025, 10300026, 10300020, 10300021, 10300019, 10300022, 10300013, 10300015, 10300006]  # Complete the list\n",
    "\n",
    "# Remove rows with missing GAME_IDs from both datasets\n",
    "games = games[~games['GAME_ID'].isin(missing_game_ids)]\n",
    "games_details = games_details[~games_details['GAME_ID'].isin(missing_game_ids)]\n",
    "\n",
    "# Verify removal\n",
    "print(f\"Remaining GAME_IDs in games: {len(games['GAME_ID'].unique())}\")\n",
    "print(f\"Remaining GAME_IDs in games_details: {len(games_details['GAME_ID'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e881556-7a34-441d-9db4-f0a8d588d9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME_IDs missing in games_details: 0\n",
      "GAME_IDs missing in games: 0\n"
     ]
    }
   ],
   "source": [
    "#checking again #checking whether all the game id in the games data set are in the games_details data set \n",
    "# Extract unique GAME_IDs from both datasets\n",
    "games_game_ids = games['GAME_ID'].unique()\n",
    "games_details_game_ids = games_details['GAME_ID'].unique()\n",
    "\n",
    "# Find GAME_IDs in games not in games_details\n",
    "missing_in_details = set(games_game_ids) - set(games_details_game_ids)\n",
    "missing_in_details_count = len(missing_in_details)\n",
    "\n",
    "# Find GAME_IDs in games_details not in games\n",
    "missing_in_games = set(games_details_game_ids) - set(games_game_ids)\n",
    "missing_in_games_count = len(missing_in_games)\n",
    "\n",
    "# Output the results\n",
    "print(f\"GAME_IDs missing in games_details: {missing_in_details_count}\")\n",
    "print(f\"GAME_IDs missing in games: {missing_in_games_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7d16301-28dc-4f18-b3b4-7cb9e2194dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique GAME_IDs in the games dataset: 26523\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the total number of unique GAME_IDs\n",
    "total_game_ids = games['GAME_ID'].nunique()\n",
    "\n",
    "print(f\"Total number of unique GAME_IDs in the games dataset: {total_game_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07df1244-0a79-44ff-b258-e6c5bb9bb122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate GAME_IDs: [22000070 22000072 22000076 22000077 22000065 22000067 22000057 22000046\n",
      " 22000049 22000051 22000053 22000055 22000042 22000044 22000032 22000034\n",
      " 22000037 22000038 22000021 22000022 22000027 22000028 22000030 22000006\n",
      " 22000007 22000011 22000013 22000015 22000018]\n",
      "Number of unique duplicate GAME_IDs: 29\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicate GAME_IDs in the games dataset\n",
    "duplicate_game_ids_games = games[games.duplicated(subset=['GAME_ID'], keep=False)]\n",
    "\n",
    "# Get unique duplicate GAME_IDs and their count\n",
    "unique_duplicate_game_ids = duplicate_game_ids_games['GAME_ID'].unique()\n",
    "number_of_duplicates = len(unique_duplicate_game_ids)\n",
    "\n",
    "print(f\"Duplicate GAME_IDs: {unique_duplicate_game_ids}\")\n",
    "print(f\"Number of unique duplicate GAME_IDs: {number_of_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "602d9b07-c1d2-4b76-82b4-82a2c4f014f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining GAME_IDs: [22200477 22200478 22200466 ... 11400005 11400002 11400001]\n",
      "Total number of unique GAME_IDs: 26523\n"
     ]
    }
   ],
   "source": [
    "# Identify duplicate GAME_IDs (if any) and remove duplicates, keeping the first occurrence\n",
    "games = games.drop_duplicates(subset=['GAME_ID'], keep='first')\n",
    "\n",
    "# Get the remaining unique GAME_IDs\n",
    "remaining_game_ids = games['GAME_ID'].unique()\n",
    "\n",
    "# Output the results\n",
    "print(f\"Remaining GAME_IDs: {remaining_game_ids}\")\n",
    "print(f\"Total number of unique GAME_IDs: {len(remaining_game_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f30827-68bd-4df9-8176-45b174a16fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of seasons: 20\n",
      "Seasons: [2022 2021 2020 2019 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004\n",
      " 2003 2018 2017 2016 2015 2014]\n"
     ]
    }
   ],
   "source": [
    "# check how many seasons are there.\n",
    "# Get unique seasons\n",
    "unique_seasons = games['SEASON'].unique()\n",
    "number_of_seasons = len(unique_seasons)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Number of seasons: {number_of_seasons}\")\n",
    "print(f\"Seasons: {unique_seasons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "020d76b8-9106-4302-b1ac-f7f30d5bb49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of teams: 30\n",
      "Teams: {1610612737, 1610612738, 1610612739, 1610612740, 1610612741, 1610612742, 1610612743, 1610612744, 1610612745, 1610612746, 1610612747, 1610612748, 1610612749, 1610612750, 1610612751, 1610612752, 1610612753, 1610612754, 1610612755, 1610612756, 1610612757, 1610612758, 1610612759, 1610612760, 1610612761, 1610612762, 1610612763, 1610612764, 1610612765, 1610612766}\n",
      "Teams per season: \n",
      "SEASON\n",
      "2003    29\n",
      "2004    30\n",
      "2005    30\n",
      "2006    30\n",
      "2007    30\n",
      "2008    30\n",
      "2009    30\n",
      "2010    30\n",
      "2011    30\n",
      "2012    30\n",
      "2013    30\n",
      "2014    30\n",
      "2015    30\n",
      "2016    30\n",
      "2017    30\n",
      "2018    30\n",
      "2019    30\n",
      "2020    30\n",
      "2021    30\n",
      "2022    30\n",
      "Name: HOME_TEAM_ID, dtype: int64\n",
      "Teams not playing in each season: \n",
      "{2003: {1610612766}}\n"
     ]
    }
   ],
   "source": [
    "# check the total number of teams and check if all the teams played in each season.\n",
    "# Extract team IDs from both home and visitor columns\n",
    "home_team_ids = games['HOME_TEAM_ID']\n",
    "visitor_team_ids = games['VISITOR_TEAM_ID']\n",
    "\n",
    "# Combine team IDs from both columns and get unique values\n",
    "all_team_ids = set(pd.concat([home_team_ids, visitor_team_ids]).unique())\n",
    "\n",
    "# Counting the number of teams in each season\n",
    "teams_per_season = games.groupby('SEASON')['HOME_TEAM_ID'].nunique()\n",
    "\n",
    "# Check which teams played in each season\n",
    "teams_in_each_season = games.groupby('SEASON')['HOME_TEAM_ID'].apply(set).combine(\n",
    "    games.groupby('SEASON')['VISITOR_TEAM_ID'].apply(set), lambda x, y: x | y\n",
    ")\n",
    "\n",
    "# Check if all teams played in every season and identify missing teams\n",
    "teams_not_playing_in_season = {\n",
    "    season: all_team_ids.difference(teams)\n",
    "    for season, teams in teams_in_each_season.items()\n",
    "    if len(all_team_ids.difference(teams)) > 0\n",
    "}\n",
    "\n",
    "# Output the results\n",
    "print(f\"Total number of teams: {len(all_team_ids)}\")\n",
    "print(f\"Teams: {all_team_ids}\")\n",
    "print(f\"Teams per season: \\n{teams_per_season}\")\n",
    "print(f\"Teams not playing in each season: \\n{teams_not_playing_in_season}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29af9396-a04e-47b3-9e0d-8630afed1d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed from games dataset: 1286\n",
      "Rows removed from games_details dataset: 30703\n"
     ]
    }
   ],
   "source": [
    "# Filter out the rows from the 2003 season in the games dataset\n",
    "games_cleaned = games[games['SEASON'] != 2003]\n",
    "\n",
    "# Filter out the rows with GAME_IDs from the 2003 season in the games_details dataset\n",
    "season_2003_game_ids = games[games['SEASON'] == 2003]['GAME_ID']\n",
    "games_details_cleaned = games_details[~games_details['GAME_ID'].isin(season_2003_game_ids)]\n",
    "\n",
    "# Output the number of rows removed from each dataset\n",
    "rows_removed_games = games.shape[0] - games_cleaned.shape[0]\n",
    "rows_removed_games_details = games_details.shape[0] - games_details_cleaned.shape[0]\n",
    "\n",
    "print(f\"Rows removed from games dataset: {rows_removed_games}\")\n",
    "print(f\"Rows removed from games_details dataset: {rows_removed_games_details}\")\n",
    "\n",
    "# Optionally, save the cleaned datasets\n",
    "# games_cleaned.to_csv('cleaned_games.csv', index=False)\n",
    "# games_details_cleaned.to_csv('cleaned_games_details.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39ca5d64-c640-487f-be64-e0fbd0733104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of seasons after cleaning: 19\n",
      "Seasons: [2022 2021 2020 2019 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004\n",
      " 2018 2017 2016 2015 2014]\n",
      "Teams per season after cleaning: \n",
      "SEASON\n",
      "2004    30\n",
      "2005    30\n",
      "2006    30\n",
      "2007    30\n",
      "2008    30\n",
      "2009    30\n",
      "2010    30\n",
      "2011    30\n",
      "2012    30\n",
      "2013    30\n",
      "2014    30\n",
      "2015    30\n",
      "2016    30\n",
      "2017    30\n",
      "2018    30\n",
      "2019    30\n",
      "2020    30\n",
      "2021    30\n",
      "2022    30\n",
      "Name: HOME_TEAM_ID, dtype: int64\n",
      "Teams not playing in each season after cleaning: \n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "#recheck if the season 2003 is been deleted.\n",
    "# Verify the number of unique seasons remaining\n",
    "unique_seasons_after_cleaning = games_cleaned['SEASON'].unique()\n",
    "number_of_seasons_after_cleaning = len(unique_seasons_after_cleaning)\n",
    "\n",
    "# Count the number of teams per season\n",
    "teams_per_season_after_cleaning = games_cleaned.groupby('SEASON')['HOME_TEAM_ID'].nunique()\n",
    "\n",
    "# Teams playing in each season\n",
    "teams_in_each_season_after_cleaning = games_cleaned.groupby('SEASON')['HOME_TEAM_ID'].apply(set).combine(\n",
    "    games_cleaned.groupby('SEASON')['VISITOR_TEAM_ID'].apply(set), lambda x, y: x | y\n",
    ")\n",
    "\n",
    "# List all unique team IDs\n",
    "all_team_ids_after_cleaning = set(pd.concat([games_cleaned['HOME_TEAM_ID'], games_cleaned['VISITOR_TEAM_ID']]).unique())\n",
    "\n",
    "# Identify teams not playing in each season\n",
    "teams_not_playing_in_season_after_cleaning = {\n",
    "    season: all_team_ids_after_cleaning.difference(teams)\n",
    "    for season, teams in teams_in_each_season_after_cleaning.items()\n",
    "    if len(all_team_ids_after_cleaning.difference(teams)) > 0\n",
    "}\n",
    "\n",
    "# Output the results\n",
    "print(f\"Number of seasons after cleaning: {number_of_seasons_after_cleaning}\")\n",
    "print(f\"Seasons: {unique_seasons_after_cleaning}\")\n",
    "print(f\"Teams per season after cleaning: \\n{teams_per_season_after_cleaning}\")\n",
    "print(f\"Teams not playing in each season after cleaning: \\n{teams_not_playing_in_season_after_cleaning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a964bf05-8630-49c2-b9e2-f78e34ace7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GAME_DATE_EST   GAME_ID  SEASON  TEAM_ID_home  PTS_home  FG_PCT_home  \\\n",
      "0    2022-12-22  22200477    2022    1610612740     126.0        0.484   \n",
      "1    2022-12-22  22200478    2022    1610612762     120.0        0.488   \n",
      "2    2022-12-21  22200466    2022    1610612739     114.0        0.482   \n",
      "3    2022-12-21  22200467    2022    1610612755     113.0        0.441   \n",
      "4    2022-12-21  22200468    2022    1610612737     108.0        0.429   \n",
      "\n",
      "   FT_PCT_home  FG3_PCT_home  AST_home  REB_home  TEAM_ID_away  PTS_away  \\\n",
      "0        0.926         0.382      25.0      46.0    1610612759     117.0   \n",
      "1        0.952         0.457      16.0      40.0    1610612764     112.0   \n",
      "2        0.786         0.313      22.0      37.0    1610612749     106.0   \n",
      "3        0.909         0.297      27.0      49.0    1610612765      93.0   \n",
      "4        1.000         0.378      22.0      47.0    1610612741     110.0   \n",
      "\n",
      "   FG_PCT_away  FT_PCT_away  FG3_PCT_away  AST_away  REB_away  HOME_TEAM_WINS  \n",
      "0        0.478        0.815         0.321      23.0      44.0               1  \n",
      "1        0.561        0.765         0.333      20.0      37.0               1  \n",
      "2        0.470        0.682         0.433      20.0      46.0               1  \n",
      "3        0.392        0.735         0.261      15.0      46.0               1  \n",
      "4        0.500        0.773         0.292      20.0      47.0               0  \n"
     ]
    }
   ],
   "source": [
    "# Columns to remove\n",
    "columns_to_remove = [ 'GAME_STATUS_TEXT', 'HOME_TEAM_ID', 'VISITOR_TEAM_ID']\n",
    "\n",
    "# Remove the specified columns\n",
    "games_data = games_cleaned.drop(columns=columns_to_remove)\n",
    "\n",
    "# Display the first few rows of the cleaned dataset to verify\n",
    "print(games_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d171f0e9-bb17-478d-9586-05379a89057d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:\\Users\\Daphne\\OneDrive\\Documents\\NBA data set\\games_home_away.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Convert as an excel file \n",
    "save_path = r\"C:\\Users\\Daphne\\OneDrive\\Documents\\NBA data set\\games_home_away.xlsx\"\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "games_data.to_excel(save_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f96538c3-d0bc-4230-8205-055bfceb5efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME_DATE_EST     0\n",
      "GAME_ID           0\n",
      "SEASON            0\n",
      "TEAM_ID_home      0\n",
      "PTS_home          0\n",
      "FG_PCT_home       0\n",
      "FT_PCT_home       0\n",
      "FG3_PCT_home      0\n",
      "AST_home          0\n",
      "REB_home          0\n",
      "TEAM_ID_away      0\n",
      "PTS_away          0\n",
      "FG_PCT_away       0\n",
      "FT_PCT_away       0\n",
      "FG3_PCT_away      0\n",
      "AST_away          0\n",
      "REB_away          0\n",
      "HOME_TEAM_WINS    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values_summary = games_data.isnull().sum()\n",
    "\n",
    "# Output the result\n",
    "print(missing_values_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d7521-974b-4400-aca0-baf5bb4e1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from an Excel file\n",
    "games_details_cleaned = pd.read_excel(r\"C:\\Users\\Daphne\\OneDrive\\Documents\\NBA data set\\nba gamesgames_details_cleaned.xlsx\")\n",
    "\n",
    "# Ensure the COMMENT column is treated as strings\n",
    "games_details_cleaned['COMMENT'] = games_details_cleaned['COMMENT'].astype(str)\n",
    "\n",
    "# Define comments to filter out\n",
    "comments_to_filter = (\n",
    "    \"DNP|DND|NWT|Did Not Dress|Not With Team|Not with team|DNT|INJ|Did Not Travel|\"\n",
    "    \"NBA Suspension|Did not dress|MWT|Will Not Play|OUT|Inactive|NOT WITH TEAM - FLU|\"\n",
    "    \"NOT WITH TEAM - LEFT HIP STRAIN|NOT WITH TEAM - PERSONAL REASONS|\"\n",
    "    \"NOT WITH TEAM - LEFT KNEE SURGERY|NOT WITH TEAM - UPPER RESPIRATORY INFECT|\"\n",
    "    \"NBA SUSPENSION|Did not Dress - Left Wrist Sprain\"\n",
    ")\n",
    "\n",
    "# Remove rows with specified comments\n",
    "games_details_filtered = games_details_cleaned[\n",
    "    ~games_details_cleaned['COMMENT'].str.contains(comments_to_filter, na=False)\n",
    "]\n",
    "\n",
    "# Specifically remove the row with GAME_ID 11700036 and PLAYER_ID 204022\n",
    "games_details_filtered = games_details_filtered[\n",
    "    ~((games_details_filtered['GAME_ID'] == 11700036) & (games_details_filtered['PLAYER_ID'] == 204022))\n",
    "]\n",
    "\n",
    "# Display the first few rows of the filtered dataset to verify the removal\n",
    "print(games_details_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e7a03-65ce-4191-9dd5-abff07466c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values_summary = games_details_filtered.isnull().sum()\n",
    "\n",
    "# Output the result\n",
    "print(missing_values_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb6057-87dd-433b-b12c-3152f45e5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to save the filtered dataset\n",
    "filtered_save_path = r\"C:\\Users\\Daphne\\OneDrive\\Documents\\NBA data set\\nba gamesgames_details_cleaned.xlsx\"\n",
    "\n",
    "# Save the filtered DataFrame to an Excel file\n",
    "games_details_filtered.to_excel(filtered_save_path, index=False)\n",
    "\n",
    "print(f\"Filtered data saved to {filtered_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17d06a-5ba5-43a0-81fc-1f695138ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "games_details_filtered = pd.read_excel(r\"C:\\Users\\Daphne\\OneDrive\\Documents\\NBA data set\\nba gamesgames_details_cleaned.xlsx\")\n",
    "\n",
    "# Columns to check for missing values\n",
    "columns_with_missing_values = [\n",
    "    'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT',\n",
    "    'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PTS'\n",
    "]\n",
    "\n",
    "# Find rows where all specified columns have missing values\n",
    "rows_with_all_missing = games_details_filtered[\n",
    "    games_details_filtered[columns_with_missing_values].isnull().all(axis=1)\n",
    "]\n",
    "\n",
    "# Display the rows with all missing values in the specified columns\n",
    "print(rows_with_all_missing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
